{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61a4abcd-b2ed-49ed-bb6a-db960a47d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import soundfile\n",
    "import librosa\n",
    "import torchlibrosa\n",
    "from panns_inference import AudioTagging\n",
    "#STFT - Short-time Fourier transform\n",
    "\n",
    "#The short-time Fourier transform (STFT) is a Fourier-related transform used to determine the sinusoidal \n",
    "#frequency and phase content of local sections of a signal as it changes over time.[1] In practice, the \n",
    "#procedure for computing STFTs is to divide a longer time signal into shorter segments of equal length and \n",
    "#then compute the Fourier transform separately on each shorter segment. This reveals the Fourier spectrum \n",
    "#on each shorter segment. One then usually plots the changing spectra as a function of time, \n",
    "#known as a spectrogram or waterfall plot, such as commonly used in software defined radio (SDR) based \n",
    "#spectrum displays. Full bandwidth displays covering the whole range of an SDR commonly use fast Fourier transforms (FFTs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a89b3ec-0b66-437c-b55f-46fe689fa044",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"artifacts/Cnn14_mAP=0.431.pth\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "168e3dd5-5c56-46fd-8189-729cc3ce608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: C:\\Users\\RomanKyrkalo/panns_data/Cnn14_mAP=0.431.pth\n",
      "GPU number: 1\n",
      "Bird vocalization, bird call, bird song :  0.5647661089897156\n",
      "Environmental noise :  0.41335853934288025\n",
      "Bird :  0.38755905628204346\n",
      "Chirp, tweet :  0.3797639310359955\n",
      "Outside, rural or natural :  0.0777573436498642\n",
      "Music :  0.06243884563446045\n",
      "Animal :  0.030938906595110893\n",
      "Speech :  0.027243217453360558\n",
      "Owl :  0.020749123767018318\n",
      "Insect :  0.016712162643671036\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from panns_inference import AudioTagging, labels\n",
    "\n",
    "audio_path = r\"C:/Users/RomanKyrkalo/Downloads/download.wav\"\n",
    "\n",
    "# 1) Load mono audio at 32 kHz\n",
    "y, sr = librosa.load(audio_path, sr=32000, mono=True)\n",
    "\n",
    "# 2) Add batch dimension: (1, T)\n",
    "y = y[None, :]\n",
    "\n",
    "# 3) Run inference\n",
    "model = AudioTagging(checkpoint_path=None)  # will download CNN14 weights on first use\n",
    "clipwise_scores, embedding = model.inference(y)  # clipwise_scores: (1, 527)\n",
    "\n",
    "# 4) Show top-10 labels\n",
    "topk = np.argsort(-clipwise_scores[0])[:10]\n",
    "for k in topk:\n",
    "    print(labels[k], \": \", float(clipwise_scores[0, k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273d0232-7eac-40e7-b4f9-b0d116b7eec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
